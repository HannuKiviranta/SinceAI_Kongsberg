ğŸš¢ COLREG Sound Signal Classifier (Autonomous Vessel Stack)This repository contains the Machine Learning pipeline, model architecture, and deployment environment (via Docker) for classifying maritime COLREG maneuvering and warning signals from pre-computed Mel Spectrogram features.The solution addresses the critical challenge of recognizing standardized sequences of short (S) and long (L) blasts (e.g., S-S-S for "Astern Propulsion") under realistic, noisy maritime conditions, providing input for automated navigation systems.âš™ï¸ Core Technology & ArchitectureThe classification is performed using a specialized Deep Learning model designed for sequential audio features:Feature Extraction: Mel Spectrograms (2D time-frequency representations) are used as input, capturing both the horn's frequency content and the precise timing of the blasts.Model: A Convolutional Neural Network (CNN)  filters noise and extracts spectral features, feeding its output into a Gated Recurrent Unit (GRU) (a type of Recurrent Neural Network).Sequence Modeling: The GRU learns the temporal patterns (the sequence of S and L blasts) which define the COLREG signal, making it robust to variations in horn timbre and environmental noise.  
  
ğŸ“ Repository Structure.  
â”œâ”€â”€ colreg_features/  
â”‚   â”œâ”€â”€ features/  
â”‚   â”‚   â”œâ”€â”€ Alter_Starboard_001.npy  # Your 2D Mel Spectrogram Feature Files  
â”‚   â”‚   â””â”€â”€ ...  
â”‚   â””â”€â”€ labels.npy                  # Metadata for all features (Class ID, Path)  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ model.py                    # (Optional: Contains the ColregClassifier class)  
â”‚   â”œâ”€â”€ train_colreg_classifier.py  # Primary script: loads features, trains model, saves weights  
â”‚   â””â”€â”€ predict.py                  # **REQUIRED:** Inference script for real-time classification  
â”œâ”€â”€ deployment/  
â”‚   â”œâ”€â”€ Dockerfile                  # Defines the container environment and dependencies  
â”‚   â””â”€â”€ requirements.txt            # Python dependencies (PyTorch, Librosa, NumPy)  
â”œâ”€â”€ docs/  
â”‚   â””â”€â”€ one_pager_summary.pdf       # Submission: Project summary and findings  
â”œâ”€â”€ test_samples/  
â”‚   â”œâ”€â”€ example_sss_horn.wav        # Submission: Example raw audio files for testing  
â”‚   â””â”€â”€ example_noise_only.wav  
â”œâ”€â”€ .gitignore                      # Ensures large artifacts (data, model files) are ignored  
â””â”€â”€ README.md  
ğŸ› ï¸ PrerequisitesTo build and run the training pipeline, you need:Docker: Must be installed and running on your system.Data: Your pre-computed Mel Spectrogram features (as NumPy .npy files) must be placed in the colreg_features/features/ subdirectory, and the corresponding labels.npy metadata file must be present in the colreg_features/ root.ğŸš€ Quick Start (Dockerized Training)The training process is fully containerized, ensuring a reproducible environment and simplifying deployment.  
1. Build the Training ImageNavigate to the project root directory and execute the following command to build the Docker image using the configuration defined in deployment/Dockerfile:docker build -t colreg-trainer ./deployment  
2. Run the TrainingExecute the training script within the container. The -v (volume) flags are critical: they map your local data and source code directories into the container, allowing the trained model to be saved back to your host machine.# Ensure you are in the project root directory:  
docker run --rm \  
  -v "$(pwd)/colreg_features:/app/colreg_features" \  
  -v "$(pwd)/src:/app/src" \  
  -v "$(pwd):/app" \  
  colreg-trainer python src/train_colreg_classifier.py  
Output: The command will output the loss and validation accuracy for each epoch, and save the final best model weights as colreg_classifier_best.pth in your project root directory.3. Deployment (Inference)Once the model is trained, the next step is to create the predict.py script. This script will load the colreg_classifier_best.pth file and be wrapped in a final, smaller Docker image for real-time edge deployment. You will need to define a similar Docker run command to classify new input .wav files.
